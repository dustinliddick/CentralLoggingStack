#########
# INPUT #
#########
input {
        redis {
                host => "10.38.2.65"
                data_type => "list"
                key => "logstash"
        }
}
########################
# FILTERING / TAGGING  #
########################
filter {
        if [type] == "syslog" {
                mutate {
                        add_tag => [ "RHEL" ]
                }
        }
        if [type] == "firewall" {
        		mutate {
        				add_tag => [ "Cisco-ASA" ]
        		}
        }
        if [type] == "VMware" {
                mutate {
                        add_tag => "VMware"
                }
        }
        if [type] == "vCenter" {
                mutate {
                        add_tag => "vCenter"
                }
        }
        if [type] == "eventlog" {
                mutate {
                        add_tag => [ "WindowsEventLog" ]
                }
        }
        if [type] == "apache" {
                mutate {
                       add_tag => [ "apache" ]
                }
        }
        if [type] == "iis" {
                mutate {
                        add_tag => [ "IIS" ]
                }
        }
}
############################################
# First layer of normal log parsing #
############################################

##########
# SYSLOG #
##########
filter {
        if "RHEL" in [tags] {
                grok {
                        match => [ "message", "<%{POSINT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" ]
                        add_field => [ "received_at", "%{@timestamp}" ]
                        add_field => [ "received_from", "%{host}" ]
                }
                dns {
                        reverse => [ "hostname" ]
                }
                syslog_pri { }
                date {
                        match => [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM dd HH:mm:ss" ]
                }
                if !("_grokparsefailure" in [tags]) {
                        mutate {
                                replace => [ "host", "%{syslog_hostname}" ]
                                replace => [ "@source_host", "%{syslog_hostname}" ]
                                replace => [ "@message", "%{syslog_message}" ]
                        }
                }
        }
}
############
# EventLog #
############
filter {
        if [tag] == "eventlog" {
                mutate {
                        lowercase => [ "EventType", "FileName", "Hostname", "Severity" ]
                }
                mutate {
                        rename => [ "Hostname", "@source_host" ]
                }
                date {
                        match => [ "EventReceivedTime", "UNIX" ]
                }
                mutate {
                        rename => [ "Message", "@message" ]
                        rename => [ "Severity", "eventlog_severity" ]
                        rename => [ "SeverityValue", "eventlog_severity_code" ]
                        rename => [ "Channel", "eventlog_channel" ]
                        rename => [ "SourceName", "eventlog_program" ]
                        rename => [ "SourceModuleName", "nxlog_input" ]
                        rename => [ "Category", "eventlog_category" ]
                        rename => [ "EventID", "eventlog_id" ]
                        rename => [ "RecordNumber", "eventlog_record_number" ]
                        rename => [ "ProcessID", "eventlog_pid" ]
                }
        }
}
#############
# Cisco ASA #
#############
filter {
		if [tag] == "Cisco-ASA" {
 				grok {
 					patterns_dir => "/opt/logstash/patterns"
					break_on_match => false
					match => [ "raw_message", "%{CISCO_TAGGED_SYSLOG} %{WORD:Action} %{WORD:IPProtocol} src %{WORD:SourceZone}:%{IP:SourceAddress}\/%{POSINT:SourcePort} dst %{WORD:DestinationZone}:%{IP:DestinationAddress}\/%{POSINT:DestinationPort} by access-group \"%{NOTSPACE:rule}\"%{GREEDYDATA}",
                 	"raw_message", "%{CISCO_TAGGED_SYSLOG} %{WORD:Action} %{IPPROTOCOL:IPProtocol} src %{WORD:SourceZone}:%{IP:SourceAddress} dst %{WORD:DestinationZone}:%{IP:DestinationAddress} %{DATA:icmp_type_code} by access-group \"%{WORD:Rule}\"%{GREEDYDATA}",
                 	"raw_message", "%{CISCO_TAGGED_SYSLOG} %{GREEDYDATA:description}" ]
				}
				mutate {
					remove_field => [ "message", "raw_message" ]
					add_field => [ "Application", "asa_unknown" ]
					lowercase => [ "Action" ]
				}
				geoip {
					add_tag => [ "GeoIP" ]
					database => "/opt/logstash/vendor/geoip/GeoLiteCity.dat" ### Change me to location of GeoLiteCity.dat file
					source => "src_ip"
				}
		if [geoip][city_name] == "" { mutate { remove_field => "[geoip][city_name]" } }
		if [geoip][continent_code] == "" { mutate { remove_field => "[geoip][continent_code]" } }
		if [geoip][country_code2] == "" { mutate { remove_field => "[geoip][country_code2]" } }
		if [geoip][country_code3] == "" { mutate { remove_field => "[geoip][country_code3]" } }
		if [geoip][country_name] == "" { mutate { remove_field => "[geoip][country_name]" } }
		if [geoip][latitude] == "" { mutate { remove_field => "[geoip][latitude]" } }
		if [geoip][longitude] == "" { mutate { remove_field => "[geoip][longitude]" } }
		if [geoip][postal_code] == "" { mutate { remove_field => "[geoip][postal_code]" } }
		if [geoip][region_name] == "" { mutate { remove_field => "[geoip][region_name]" } }
		if [geoip][time_zone] == "" { mutate { remove_field => "[geoip][time_zone]" } }
# Parse the date
				date {
 					match => ["timestamp",
 								"MMM dd HH:mm:ss",
								"MMM d HH:mm:ss",
								"MMM dd yyyy HH:mm:ss",
								"MMM d yyyy HH:mm:ss"
								]
				}
			}
}
############################
# Second pass at filtering #
############################
## RHEL login filter ##
#filter {
#		if [tag] == "syslog" {
#				grok {
#  						type => "syslog"
#  						match => "message", "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host_target} sshd\[%{BASE10NUM}\]: Failed password for invalid user %{USERNAME:username} from %{IP:src_ip} port %{BASE10NUM:port} ssh2"
#  						add_tag => "ssh_brute_force_attack"
#					}
#				grok {
#  						type => "syslog"
#  						match => "message", "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host_target} sudo: pam_unix\(sudo:auth\): authentication failure; logname=%{USERNAME:logname} uid=%{BASE10NUM:uid} euid=%{BASE10NUM:euid} tty=%{TTY:tty} ruser=%{USERNAME:ruser} rhost=(?:%{HOSTNAME:remote_host}|\s*) user=%{USERNAME:user}"
#  						add_tag => "sudo_auth_failure"
#  					}
#				grok {
#  						type => "syslog"
#  						match => "message", "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host_target} sshd\[%{BASE10NUM}\]: Failed password for %{USERNAME:username} from %{IP:src_ip} port %{BASE10NUM:port} ssh2"
#  						add_tag => "ssh_failed_login"
#					}
#				grok {
#  						type => "syslog"
#  						match => "messge", "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host_target} sshd\[%{BASE10NUM}\]: Accepted password for %{USERNAME:username} from %{IP:src_ip} port %{BASE10NUM:port} ssh2"
#  						add_tag => "ssh_sucessful_login"
#					}
#			}
#	}
############################
# Nagios Filter for alerts #
############################

filter {
        if [type] == "syslog" {
                grok {
                        patterns_dir => "/etc/logstash/patterns"
                        match => [
                                "message", "%{SYSLOGLINE} nagios log test"
                        ]
                        add_tag => [ "nagios_check_syslog_test" ]
                        add_field => [
                                "nagios_service", "LogstashAlertTest"
                                ]
                }
        }
}
##############################################################
# Microsoft IIS logging....Use NXLOG for client side logging #
##############################################################


###################################################################################################################################
# The below filter section will be used to remove unnecessary fields to keep ES memory cache from filling up with useless data    #
# The below filter section will be where you would want to comment certain types or tags out if trying to isolate a logging issue #
###################################################################################################################################


######################################################################################################################################################
#### Multicast discovery mode ####                                                                                                                   #
# Send output to the ES cluster logstash-cluster using a predefined template                                                                         #
# The following settings will be used during the initial setup which will be used for using multicast ES nodes                                       #
# When changing to unicast discovery mode you need to comment out the following section and configure the unicast discovery mode in the next section #
######################################################################################################################################################

output {
        elasticsearch {
                cluster => "logstash-cluster"
                host => "elkes-ob-1p"
                port => "9300"
                protocol => "node"
                flush_size => 1
                manage_template => true
                template => "/opt/logstash/lib/logstash/outputs/elasticsearch/elasticsearch-template.json"
        }
if "nagios_check_syslog_test" in [tags] {
        nagios_nsca {
                host => "10.8.31.12"
                port => 5667
                send_nsca_bin => "/opt/collegis/software/nagios/nsca-2.9.1/src/send_nsca"
                nagios_host => "localhost"
                nagios_service => "LogstashAlertTest"
                nagios_status => 2
                message_format => "%{SYSLOGTIME}  %{SYSLOGHOST}"
                }
        }
}